{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "junior-valve",
   "metadata": {},
   "source": [
    "Linear (in x) model\n",
    "\n",
    "$ $$y^p$$ = m $$x$$ + b $, results in the following error\n",
    "\n",
    "$e(m, b)=\\sum_{i=0}^{n-1} ($$y^t_i$$ -m $$x_i$$ -b)^2$ <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-dancing",
   "metadata": {},
   "source": [
    "Non-linear (in x) model\n",
    "\n",
    "$ $$y^p$$ = r $$x^3$$ + s $$x^2$$  + m $$x$$ +b $, results in the following loss\n",
    "\n",
    "$e(r, s, m, b)=\\sum_{i=0}^{n-1} ($$y^t_i$$ -r \\space $$x^3_i$$ -s \\space $$x^2_i$$ -m \\space $$x_i$$ -b)^2$ <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-trial",
   "metadata": {},
   "source": [
    "$r, s, m$ and $b$ are constants. Superscript integers represent powers (exponentiation).\n",
    "\n",
    "Note that $ $$y^p$$ $ is still $\\underline {linear} $ in $r, s, m$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-california",
   "metadata": {},
   "source": [
    "$\\frac{\\partial e}{\\partial m}$ <br>\n",
    "\n",
    "\n",
    "= $\\frac {\\partial } {\\partial m} ( \\sum_{i=0}^{n-1} (y^t_i  -r \\space $$x^3_i$$ -s \\space $$x^2_i$$ -m \\space $$x_i$$ -b)^2 ) $\n",
    "\n",
    "\n",
    "$ = \\sum_{i=0}^{n-1} \\frac {\\partial (y^t_i -r \\space x^3_i -s \\space x^2_i -m \\space x_i -b)^2 } {\\partial m} $ <br>\n",
    "\n",
    "$ = \\sum_{i=0}^{n-1} 2(y^t_i -r \\space x^3_i -s \\space x^2_i -m \\space x_i -b) \\frac {\\partial (y^t_i -r \\space x^3_i -s \\space x^2_i -m \\space x_i -b) } {\\partial m} $ <br>\n",
    "\n",
    "\n",
    "$ = \\sum_{i=0}^{n-1} 2(y^t_i -r \\space x^3_i -s \\space x^2_i -m \\space x_i -b) (-x_i) $ <br>\n",
    "\n",
    "$ = -2 \\sum_{i=0}^{n-1}e_ix_i$\n",
    "\n",
    "where $ e_i = (y^t_i -r \\space x^3_i -s \\space x^2_i -m \\space x_i -b)$. Using the bar notation, where bar means average,\n",
    "\n",
    "$\\frac{1}{n} \\frac{\\partial e}{\\partial m} = -2 \\overline {ex} $. &emsp; &emsp;  &emsp; &emsp; &emsp; &emsp;  &emsp; &emsp;  &nbsp; $(1)$<br>\n",
    "\n",
    "Similarly, we can derive\n",
    "\n",
    "$\\frac{1}{n} \\frac{\\partial e}{\\partial b} = -2 \\overline {e} $, &emsp; &emsp;  &emsp; &emsp; &emsp; &emsp;  &emsp; &emsp;  &emsp; $(2)$\n",
    "\n",
    "$\\frac{1}{n} \\frac{\\partial e}{\\partial r} = -2 \\overline {ex^3} $, &emsp; &emsp;  &emsp; &emsp; &emsp; &emsp;  &emsp; &emsp;  $(3)$\n",
    "\n",
    "and\n",
    "\n",
    "$\\frac{1}{n} \\frac{\\partial e}{\\partial s} = -2 \\overline {ex^2} $. &emsp; &emsp;  &emsp; &emsp; &emsp; &emsp;  &emsp; &emsp;  $(4)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-favorite",
   "metadata": {},
   "source": [
    "Assume initial values for $m, b, r$ and $s$. Then iterate using,\n",
    "\n",
    "$m = m - C \\frac{\\partial e}{\\partial m}$\n",
    "\n",
    "$b = b - C \\frac{\\partial e}{\\partial b}$\n",
    "\n",
    "$r = r - C \\frac{\\partial e}{\\partial r}$\n",
    "\n",
    "$s = s - C \\frac{\\partial e}{\\partial s}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acquired-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch import nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "failing-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.675305481334444 5.563812220118603\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "x, y = np.loadtxt('data.txt')\n",
    "xS = 12*x-6\n",
    "print(xS.min(), xS.max())\n",
    "df = pd.DataFrame({\"x\": x, \"y_true\": y})\n",
    "noise = np.random.normal(0, 0.05, len(df))\n",
    "df['y_true'] = 2*df['x']*df['x']*df['x'] + 0.5*df['x'] + 5 + noise\n",
    "df['x3'] = df['x']*df['x']*df['x']\n",
    "df['x2'] = df['x']*df['x']\n",
    "df['x0'] = np.ones(len(df))\n",
    "df['xS'] = xS\n",
    "yt_min = df.y_true.min()\n",
    "yt_range = df.y_true.max() - yt_min\n",
    "df['y_true'] = (df['y_true'] - yt_min)/yt_range\n",
    "print(df.y_true.min(), df.y_true.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minute-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tx = torch.tensor(df[['x3','x2','x', 'x0']].to_numpy())\n",
    "#tx = torch.tensor(df[['xS', 'x0']].to_numpy())\n",
    "tx = torch.tensor(df[['x']].to_numpy())\n",
    "y_true = torch.tensor(df['y_true'].to_numpy(), dtype=torch.float).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moved-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unknown-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(1, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        input = input.float()\n",
    "        return self.lin(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greenhouse-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn(y_pred, y_true):\n",
    "#     e = y_pred - y_true\n",
    "#     return (e*e).mean()\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sustainable-tennessee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm before:  Parameter containing:\n",
      "tensor([[0.4328],\n",
      "        [0.3475],\n",
      "        [0.9688],\n",
      "        [0.5333]], requires_grad=True) None\n",
      "pm before:  Parameter containing:\n",
      "tensor([0.7166, 0.6123, 0.4462, 0.1741], requires_grad=True) None\n",
      "pm before:  Parameter containing:\n",
      "tensor([[-0.4380, -0.2316,  0.2196,  0.3195],\n",
      "        [ 0.0466,  0.3804,  0.1302,  0.0289],\n",
      "        [-0.1480,  0.4782, -0.1461, -0.1505],\n",
      "        [-0.0431, -0.1077,  0.3316,  0.3111]], requires_grad=True) None\n",
      "pm before:  Parameter containing:\n",
      "tensor([ 0.4676, -0.1799,  0.1378, -0.1362], requires_grad=True) None\n",
      "pm before:  Parameter containing:\n",
      "tensor([[ 0.3147,  0.0425, -0.4035,  0.0337]], requires_grad=True) None\n",
      "pm before:  Parameter containing:\n",
      "tensor([0.1380], requires_grad=True) None\n",
      "iter, loss:  0 tensor(0.1365, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  500 tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  1000 tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  1500 tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  2000 tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  2500 tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  3000 tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  3500 tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  4000 tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  4500 tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "iter, loss:  5000 tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "pm after:  Parameter containing:\n",
      "tensor([[ 0.2432],\n",
      "        [-0.2940],\n",
      "        [ 1.5905],\n",
      "        [ 1.1120]], requires_grad=True) tensor([[-8.2570e-07],\n",
      "        [ 2.5341e-06],\n",
      "        [ 1.3361e-06],\n",
      "        [ 5.1979e-07]])\n",
      "pm after:  Parameter containing:\n",
      "tensor([ 0.7801,  1.1402,  0.0949, -0.1321], requires_grad=True) tensor([ 2.4110e-07, -5.2080e-06,  1.4780e-06, -2.7370e-05])\n",
      "pm after:  Parameter containing:\n",
      "tensor([[-0.4096, -0.3459,  0.6908,  0.6446],\n",
      "        [ 0.0417,  0.3543,  0.1837,  0.0684],\n",
      "        [ 0.1245,  1.0266, -0.7581, -0.6433],\n",
      "        [ 0.0131, -0.1725,  0.7160,  0.5723]], requires_grad=True) tensor([[-1.2090e-06, -3.9602e-06,  5.1228e-06,  4.0983e-06],\n",
      "        [ 2.9204e-07,  6.2538e-07, -4.4156e-07, -7.3131e-08],\n",
      "        [-4.0570e-06, -8.6871e-06,  6.1351e-06,  1.0158e-06],\n",
      "        [-1.1398e-06, -3.7329e-06,  4.8290e-06,  3.8632e-06]])\n",
      "pm after:  Parameter containing:\n",
      "tensor([ 0.3052, -0.2070,  0.8326, -0.1993], requires_grad=True) tensor([-2.6028e-06,  4.6956e-07, -6.5239e-06, -2.4533e-06])\n",
      "pm after:  Parameter containing:\n",
      "tensor([[ 0.8703,  0.1160, -1.6122,  0.8203]], requires_grad=True) tensor([[8.3331e-06, 4.3420e-07, 1.2505e-05, 8.2738e-06]])\n",
      "pm after:  Parameter containing:\n",
      "tensor([-0.6776], requires_grad=True) tensor([4.0468e-06])\n",
      "loss after:  tensor(0.0021, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#print('pm before: ', pm1, pm2)\n",
    "y_pred = None\n",
    "loss = None\n",
    "lm = LinearModel()\n",
    "#lm = lm.double()\n",
    "optimizer = torch.optim.SGD(lm.parameters(), lr=C)\n",
    "for p in lm.parameters():\n",
    "    print('pm before: ', p, p.grad)\n",
    "for iter in range(5001):\n",
    "    #y_pred = forward(tx, pm1, pm2)\n",
    "    y_pred = lm(tx)\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "    if iter%500 == 0:\n",
    "        print('iter, loss: ', iter, loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#print('pm after: ', pm1, pm2)\n",
    "for p in lm.parameters():\n",
    "    print('pm after: ', p, p.grad)\n",
    "print('loss after: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "egyptian-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_pred'] = y_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "numerical-mystery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='x'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sort_values('x').plot(x=\"x\", y=[\"y_true\", \"y_pred\"], style=['o','-'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f71c93a",
   "metadata": {},
   "source": [
    "# Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402055b",
   "metadata": {},
   "source": [
    "## Description:\n",
    "To analyze and categorize tweets, a technique called Bag-of-Words (BoW) can be used to convert the tweets into numerical features. The process involves first cleaning and preparing the tweets by breaking them down into individual words and creating a vocabulary of all the unique words. Then, each tweet is represented as a feature vector using the BoW model, which counts the frequency of each word in the vocabulary and assigns it a numerical value. This allows for easier analysis and categorization of the tweets based on their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "559f1dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\python\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: gensim in c:\\users\\python\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\python\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: torch in c:\\users\\python\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\python\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\python\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\python\\lib\\site-packages (from pandas) (1.23.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\python\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\python\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\python\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\python\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\python\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\python\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\python\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\python\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\python\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\python\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\python\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\python\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas gensim scikit-learn torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbecf0b",
   "metadata": {},
   "source": [
    "## Implementation:\n",
    "This code is implementing a simple neural network for sentiment classification of tweets using cross-validation. The steps can be summarized as follows:\n",
    "\n",
    "1) Import necessary libraries: pandas, gensim, scikit-learn, and torch are imported for data handling, word embeddings, splitting the data, and neural network implementation, respectively.\n",
    "\n",
    "2) Load and preprocess data: The tweet texts and corresponding sentiment labels are loaded from online sources and combined into a single DataFrame.\n",
    "\n",
    "3) Tokenize tweets and create Word2Vec model: The tweets are tokenized, and a Word2Vec model is trained on these tokens.\n",
    "\n",
    "4) Define a function to convert tweets into embeddings: This function takes a tweet and the trained Word2Vec model as inputs and returns an averaged word embedding for the tweet.\n",
    "\n",
    "5) Convert tweets into embeddings: Each tweet in the dataset is converted into an averaged word embedding using the Word2Vec model.\n",
    "\n",
    "6) Create a custom dataset class for the tweet embeddings and sentiment labels.\n",
    "\n",
    "7) Define a neural network model: A simple feedforward neural network is defined with an input layer, a hidden layer with 128 units and ReLU activation, and an output layer with 3 units representing the 3 sentiment classes.\n",
    "\n",
    "8) Define training and evaluation functions: These functions train the neural network model using the provided data and evaluate its performance by calculating a confusion matrix.\n",
    "\n",
    "9) Perform cross-validation: The data is split into 5 folds using KFold cross-validation, and for each fold, the model is trained on the training set and evaluated on the test set. The confusion matrix, accuracy, and F1 score are calculated and printed for each fold.\n",
    "\n",
    "10) Train and evaluate the model for each fold: For each fold, the model is trained for 50 epochs using a learning rate of 1e-4 and batch size of 16. The performance of the model is then evaluated on the test set, and the confusion matrix, accuracy, and F1 score are printed.\n",
    "\n",
    "The purpose of this code is to build and evaluate a simple neural network model for sentiment classification of tweets using word embeddings and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c58fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62dc488",
   "metadata": {},
   "source": [
    "First we will load the data and preprocess it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfd39ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Load tweet texts\n",
    "text_url = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_text.txt\"\n",
    "response = requests.get(text_url)\n",
    "texts = [line.strip() for line in response.text.split('\\n') if line.strip()]\n",
    "\n",
    "# Load sentiment labels\n",
    "label_url = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/train_labels.txt\"\n",
    "response = requests.get(label_url)\n",
    "labels = [int(line.strip()) for line in response.text.split('\\n') if line.strip()]\n",
    "\n",
    "# Combine texts and labels into a single DataFrame\n",
    "data = {'sentiment': labels, 'TweetText': texts}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#df = df[['sentiment', 'TweetText']]\n",
    "#label_map = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "#df['sentiment'] = df['sentiment'].apply(lambda x: label_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ba213",
   "metadata": {},
   "source": [
    "Next, we will create the Bag-of-Words representation of the tweets using CountVectorizer from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6d0a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize tweets and create Word2Vec model\n",
    "tweets = [t.split() for t in df['TweetText']]\n",
    "word2vec_model = Word2Vec(sentences=tweets, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def tweet_to_embedding(tweet, word2vec_model):\n",
    "    tokens = tweet.split()\n",
    "    embeddings = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    if not embeddings:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "X = np.array([tweet_to_embedding(tweet, word2vec_model) for tweet in df['TweetText']])\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed843378",
   "metadata": {},
   "source": [
    "Now, we will create the custom dataset class and DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "988fd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample = self.X[idx]\n",
    "        y_sample = self.y[idx]\n",
    "        return x_sample, y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef24b1",
   "metadata": {},
   "source": [
    "Lets define the neural network model for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d07f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model\n",
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ClassifierModel, self).__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return self.lin(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d90f9",
   "metadata": {},
   "source": [
    "Finally, we will train the classifier using the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b17cd014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "def train(model, data_loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d5a6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            output = model(x_batch)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    return confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da10ae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5 confusion matrix:\n",
      "[[  40  948  440]\n",
      " [  33 2842 1267]\n",
      " [  21 1453 2079]]\n",
      "Accuracy: 0.5438\n",
      "F1 Score: 0.5039\n",
      "\n",
      "Fold 2/5 confusion matrix:\n",
      "[[  62  984  383]\n",
      " [  48 2989 1048]\n",
      " [  20 1708 1881]]\n",
      "Accuracy: 0.5406\n",
      "F1 Score: 0.5016\n",
      "\n",
      "Fold 3/5 confusion matrix:\n",
      "[[  79 1021  335]\n",
      " [  68 3175  865]\n",
      " [  52 1885 1643]]\n",
      "Accuracy: 0.5368\n",
      "F1 Score: 0.4966\n",
      "\n",
      "Fold 4/5 confusion matrix:\n",
      "[[  58 1100  243]\n",
      " [  69 3356  734]\n",
      " [  39 2045 1479]]\n",
      "Accuracy: 0.5363\n",
      "F1 Score: 0.4903\n",
      "\n",
      "Fold 5/5 confusion matrix:\n",
      "[[  48  869  483]\n",
      " [  42 2809 1328]\n",
      " [  25 1478 2041]]\n",
      "Accuracy: 0.5369\n",
      "F1 Score: 0.4998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    train_dataset = TweetDataset(X_train, y_train)\n",
    "    test_dataset = TweetDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    input_size = word2vec_model.vector_size\n",
    "    model = ClassifierModel(input_size).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        train(model, train_loader, loss_fn, optimizer, device)\n",
    "\n",
    "    y_true = y_test\n",
    "    y_pred = []\n",
    "    for _, batch in enumerate(test_loader):\n",
    "        inputs, _ = batch\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold+1}/{num_folds} confusion matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc6949",
   "metadata": {},
   "source": [
    "## Output :\n",
    "This output shows a breakdown of the performance of a machine learning model for sentiment classification. The model was trained on a dataset divided into five parts, with each part being used as a test set once while the other four were used as training sets. The confusion matrix for each fold shows how well the model performed in predicting the sentiment of the test data, comparing its predictions with the actual sentiment labels. The three sentiment categories used were negative, neutral, and positive. Overall, the confusion matrix helps evaluate the model's accuracy, precision, and recall for each sentiment class. \n",
    "The table above shows the comparison between the actual and predicted class labels, where each row represents the true class and each column represents the predicted class.\n",
    "\n",
    "For example, in the first fold, the output confusion matrix interprets the following: \n",
    "    a) 40 negative tweets were correctly classified, 948 were misclassified as neutral, and 440 as positive.\n",
    "    b) 33 neutral tweets were misclassified as negative, 2842 were correctly classified, and 1267 were misclassified as positive.\n",
    "    c) 21 positive tweets were misclassified as negative, 1453 were misclassified as neutral, and 2079 were correctly classified.\n",
    "A high number of correct predictions along the diagonal of the confusion matrix and low numbers in the off-diagonal elements indicate a good classifier. The current confusion matrices show that the model seems to perform well for class 1 (neutral) but has a more challenging time with class 0 (negative) and class 2 (positive).\n",
    "\n",
    "Accuracy: 0.5438\n",
    "The accuracy is the ratio of the correctly classified instances to the total instances in the test set. An accuracy of 0.5438 means that 54.38% of the instances in the test set were correctly classified by the model in the first fold.\n",
    "\n",
    "F1 Score: 0.5039\n",
    "The F1 score is the harmonic mean of precision and recall, and it is a measure that takes both false positives and false negatives into account. The F1 score ranges from 0 to 1, with 1 being the best possible score. An F1 score of 0.5039 indicates that the model has moderate performance in balancing precision and recall for this specific fold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45214c86",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "This method involves utilizing a basic Bag-of-Words model to convert the tweets into numerical features, and implementing a neural network for classification. The Bag-of-Words model involves representing each tweet as a frequency count of the words in the vocabulary, while the neural network analyzes these numerical features to classify the tweets into predefined categories. By combining these two techniques, the model can effectively analyze and categorize tweets based on their content.\n",
    "The performance of the model depends on the performance of all the folds. The model's performance is slightly better than random guessing for a three-class classification problem. It shows that the model has some predictive ability, but there is significant room for improvement. It is essential to look into possible improvements to the model, such as using a more sophisticated architecture, better pre-processing of the input data, or leveraging additional features to enhance the performance of the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
